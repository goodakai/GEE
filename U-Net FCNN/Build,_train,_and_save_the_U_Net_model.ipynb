{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPJGjucsafufFiTOmcSru+z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/goodakai/GEE/blob/main/Build%2C_train%2C_and_save_the_U_Net_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# python code for mapping leucogranite based on GEE\n",
        "# author: Dakai Guo,Ziye Wang\n",
        "# contact: Ziye Wang (Email: ziyewang@cug.edu.cn)"
      ],
      "metadata": {
        "id": "6_IaObpgRbyN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "96wpCdJ61AcS"
      },
      "outputs": [],
      "source": [
        "# mount google cloud drive and GEE API\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import ee\n",
        "ee.Authenticate()\n",
        "ee.Initialize(project='my-project')# GEE Project Title"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary packages\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models"
      ],
      "metadata": {
        "id": "7dQFSyiz6rxt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the GCP project ID and GCS BUCKET ID\n",
        "PROJECT = 'GCP project ID'\n",
        "OUTPUT_BUCKET = 'GCS BUCKET ID'\n",
        "# Preset input and output variables\n",
        "INPUT_BANDS  = ['a3n','a04','a06','a07','s11']\n",
        "OUTPUT_BANDS = ['lithology']\n",
        "N_CLASSES = len(OUTPUT_BANDS)\n",
        "BANDS = INPUT_BANDS + OUTPUT_BANDS\n",
        "COLUMNS = [\n",
        "  tf.io.FixedLenFeature(shape=[256, 256], dtype=tf.float32)# Preset Data Shapes\n",
        "  for k in BANDS\n",
        "]\n",
        "FEATURES_DICT = dict(zip(BANDS, COLUMNS))"
      ],
      "metadata": {
        "id": "aDvX0FgB1a32"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Call the training label vector file stored in GEE\n",
        "labelfc = ee.FeatureCollection(\"Asset ID\");\n",
        "# Vector to image\n",
        "label_im = labelfc.reduceToImage(['Lithology'], 'mean')\n",
        "# Determine the training data area\n",
        "aoi = labelfc.geometry().bounds();\n",
        "# Call the pre-processed remote sensing data stored in GEE\n",
        "rsimage = ee.Image(\"Asset ID\").select(INPUT_BANDS)\n",
        "# Combining remote sensing data with labels\n",
        "trainimage = rsimage.addBands(label_im.select(['mean'],['lithology'])).clip(aoi)\n",
        "print(trainimage.getInfo())"
      ],
      "metadata": {
        "id": "UJMC7bA_-hCh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate training data export task\n",
        "task_config = {\n",
        "    'image': trainimage,\n",
        "    'description': '5b_tirtraindata256',\n",
        "    'bucket': OUTPUT_BUCKET,\n",
        "    'fileNamePrefix': '5b_tirtraining256',\n",
        "    'region': aoi,\n",
        "    'scale': 30,\n",
        "    'fileFormat': 'TFRecord',\n",
        "    'maxPixels': 1e13,\n",
        "    'formatOptions': {\n",
        "        'patchDimensions': [32, 32],# Specify the core size for ​​one tiles\n",
        "        'kernelSize': [224, 224],# Specify the buffer size for ​​one tiles\n",
        "        'compressed': True,\n",
        "        'maxFileSize': 104857600 * 10\n",
        "    }\n",
        "}"
      ],
      "metadata": {
        "id": "AQFzcbd_2ZNY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Start export task\n",
        "task = ee.batch.Export.image.toCloudStorage(**task_config)\n",
        "task.start()"
      ],
      "metadata": {
        "id": "fjzdLIq14MFF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(task.status())"
      ],
      "metadata": {
        "id": "C8rKprCF4VBW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load training data from GCS and Augment\n",
        "class Augment(tf.keras.layers.Layer):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def call(self, inputs, labels):\n",
        "        # Flip along the X and Y axes\n",
        "        augmented_inputs = [inputs, tf.image.flip_left_right(inputs), tf.image.flip_up_down(inputs)]\n",
        "        augmented_labels = [labels, tf.image.flip_left_right(labels), tf.image.flip_up_down(labels)]\n",
        "\n",
        "        # Rotate 3 times 90°\n",
        "        for k in range(1, 3):\n",
        "            augmented_inputs.append(tf.image.rot90(inputs, k=k))\n",
        "            augmented_labels.append(tf.image.rot90(labels, k=k))\n",
        "\n",
        "        # Merge all augmented images\n",
        "        augmented_inputs = tf.concat(augmented_inputs, axis=0)\n",
        "        augmented_labels = tf.concat(augmented_labels, axis=0)\n",
        "\n",
        "        return augmented_inputs, augmented_labels\n",
        "\n",
        "# Parses a single TFRecord example into a dictionary of features\n",
        "def parse_tfrecord(example_proto):\n",
        "    return tf.io.parse_single_example(example_proto, FEATURES_DICT)\n",
        "\n",
        "def to_tuple(inputs):\n",
        "    # Expand each input channel (from INPUT_BANDS) by adding a new axis at the end\n",
        "    # This turns each channel into a tensor of shape (height, width, 1)\n",
        "    input_channels = [tf.expand_dims(inputs[name], axis=-1) for name in INPUT_BANDS]\n",
        "    # Concatenate all channels along the last axis to get a tensor of shape (height, width, num_channels)\n",
        "    inputs_concatenated = tf.concat(input_channels, axis=-1)\n",
        "    # Get the output label and cast it to float32 type\n",
        "    labels = tf.cast(inputs[OUTPUT_BANDS[0]], tf.float32)\n",
        "    # Expand the label by adding a new axis at the end, resulting in shape (height, width, 1)\n",
        "    labels = tf.expand_dims(labels, axis=-1)\n",
        "    return inputs_concatenated, labels\n",
        "\n",
        "def filter_black_borders(inputs, labels):\n",
        "    # Create a boolean mask where True means the pixel is non-zero\n",
        "    mask = tf.reduce_any(tf.not_equal(inputs, 0), axis=-1)\n",
        "    # Check if all pixels in the image are non-zero\n",
        "    all_non_zero = tf.reduce_all(mask)\n",
        "    return all_non_zero\n",
        "\n",
        "def get_dataset(pattern, batch_size):\n",
        "    dataset = tf.data.Dataset.list_files(pattern).interleave(\n",
        "        lambda filename: tf.data.TFRecordDataset(filename, compression_type='GZIP'))\n",
        "    dataset = dataset.map(parse_tfrecord, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    dataset = dataset.map(to_tuple, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    dataset = dataset.filter(filter_black_borders)\n",
        "    dataset = dataset.cache()\n",
        "    dataset = dataset.shuffle(512)\n",
        "    dataset = dataset.map(lambda inputs, labels: Augment()(inputs, labels), num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    dataset = dataset.unbatch()\n",
        "    dataset = dataset.batch(batch_size)\n",
        "    dataset = dataset.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "    return dataset\n",
        "\n",
        "# Create the training dataset with batch size of 6\n",
        "batch_size = 6\n",
        "training_dataset = get_dataset(\"Path of training data\", batch_size)\n",
        "\n",
        "# Inspect the first element from the training dataset.\n",
        "for inputs, outputs in training_dataset.take(1):\n",
        "    print(\"inputs:\")\n",
        "    print(f\"  {inputs.dtype.name} {inputs.shape}\")\n",
        "    print(f\"outputs: {outputs.dtype.name} {outputs.shape}\")\n"
      ],
      "metadata": {
        "id": "xYP1FEWz4WIo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the size of the training and test sets\n",
        "DATASET_SIZE = len(list(training_dataset))\n",
        "train_size = int(0.8 * DATASET_SIZE)\n",
        "val_size = int(0.2 * DATASET_SIZE)\n",
        "\n",
        "# Divide the training set\n",
        "train_dataset = training_dataset.take(train_size)\n",
        "\n",
        "# Divide validation set\n",
        "val_dataset = training_dataset.skip(train_size).take(val_size)"
      ],
      "metadata": {
        "id": "AwKobafs7H3H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Building the U-Net model\n",
        "def get_unet_model(input_shape, num_classes):\n",
        "    inputs = tf.keras.Input(shape=[None, None, len(INPUT_BANDS)])\n",
        "\n",
        "    conv1 = layers.Conv2D(32, (3, 3), activation=\"relu\", padding=\"same\")(inputs)\n",
        "    conv1 = layers.Conv2D(32, (3, 3), activation=\"relu\", padding=\"same\")(conv1)\n",
        "    pool1 = layers.MaxPooling2D(pool_size=(2, 2))(conv1)\n",
        "\n",
        "    conv2 = layers.Conv2D(64, (3, 3), activation=\"relu\", padding=\"same\")(pool1)\n",
        "    conv2 = layers.Conv2D(64, (3, 3), activation=\"relu\", padding=\"same\")(conv2)\n",
        "    pool2 = layers.MaxPooling2D(pool_size=(2, 2))(conv2)\n",
        "\n",
        "    conv3 = layers.Conv2D(128, (3, 3), activation=\"relu\", padding=\"same\")(pool2)\n",
        "    conv3 = layers.Conv2D(128, (3, 3), activation=\"relu\", padding=\"same\")(conv3)\n",
        "    pool3 = layers.MaxPooling2D(pool_size=(2, 2))(conv3)\n",
        "\n",
        "    conv4 = layers.Conv2D(256, (3, 3), activation=\"relu\", padding=\"same\")(pool3)\n",
        "    conv4 = layers.Conv2D(256, (3, 3), activation=\"relu\", padding=\"same\")(conv4)\n",
        "    pool4 = layers.MaxPooling2D(pool_size=(2, 2))(conv4)\n",
        "\n",
        "    conv5 = layers.Conv2D(512, (3, 3), activation=\"relu\", padding=\"same\")(pool4)\n",
        "    conv5 = layers.Conv2D(512, (3, 3), activation=\"relu\", padding=\"same\")(conv5)\n",
        "\n",
        "    up6 = layers.concatenate([layers.UpSampling2D(size=(2, 2))(conv5), conv4])\n",
        "    conv6 = layers.Conv2D(256, (3, 3), activation=\"relu\", padding=\"same\")(up6)\n",
        "    conv6 = layers.Conv2D(256, (3, 3), activation=\"relu\", padding=\"same\")(conv6)\n",
        "\n",
        "    up7 = layers.concatenate([layers.UpSampling2D(size=(2, 2))(conv6), conv3])\n",
        "    conv7 = layers.Conv2D(128, (3, 3), activation=\"relu\", padding=\"same\")(up7)\n",
        "    conv7 = layers.Conv2D(128, (3, 3), activation=\"relu\", padding=\"same\")(conv7)\n",
        "\n",
        "    up8 = layers.concatenate([layers.UpSampling2D(size=(2, 2))(conv7), conv2])\n",
        "    conv8 = layers.Conv2D(64, (3, 3), activation=\"relu\", padding=\"same\")(up8)\n",
        "    conv8 = layers.Conv2D(64, (3, 3), activation=\"relu\", padding=\"same\")(conv8)\n",
        "\n",
        "    up9 = layers.concatenate([layers.UpSampling2D(size=(2, 2))(conv8), conv1])\n",
        "    conv9 = layers.Conv2D(32, (3, 3), activation=\"relu\", padding=\"same\")(up9)\n",
        "    conv9 = layers.Conv2D(32, (3, 3), activation=\"relu\", padding=\"same\")(conv9)\n",
        "\n",
        "    conv10 = layers.Conv2D(num_classes, (1, 1), activation=\"sigmoid\")(conv9)\n",
        "\n",
        "    model = models.Model(inputs, outputs=conv10)\n",
        "    return model\n",
        "model = get_unet_model([256, 256, len(INPUT_BANDS)], 1)"
      ],
      "metadata": {
        "id": "6e-qD6fh7O0m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting the learning rate and optimizer\n",
        "learning_rate = 0.0001\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "# Compile the model\n",
        "model.compile(\n",
        "    optimizer=optimizer,\n",
        "    loss=\"binary_crossentropy\",\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "# Training the model\n",
        "model.fit(\n",
        "    train_dataset,\n",
        "    validation_data=val_dataset,\n",
        "    epochs=200,\n",
        ")"
      ],
      "metadata": {
        "id": "ou0EPYg17_Ax"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Deserialize and package the trained model\n",
        "class DeSerializeInput(tf.keras.layers.Layer):\n",
        "  def __init__(self, **kwargs):\n",
        "    super().__init__(**kwargs)\n",
        "\n",
        "  def call(self, inputs_dict):\n",
        "    return {\n",
        "      k: tf.map_fn(lambda x: tf.io.parse_tensor(x, tf.float32),\n",
        "                   tf.io.decode_base64(v),\n",
        "                   fn_output_signature=tf.float32)\n",
        "        for (k, v) in inputs_dict.items()\n",
        "    }\n",
        "\n",
        "  def get_config(self):\n",
        "    config = super().get_config()\n",
        "    return config\n",
        "\n",
        "\n",
        "class ReSerializeOutput(tf.keras.layers.Layer):\n",
        "  def __init__(self, **kwargs):\n",
        "    super().__init__(**kwargs)\n",
        "\n",
        "  def call(self, output_tensor):\n",
        "    return tf.map_fn(lambda x: tf.io.encode_base64(tf.io.serialize_tensor(x)),\n",
        "                    output_tensor,\n",
        "                    fn_output_signature=tf.string)\n",
        "\n",
        "  def get_config(self):\n",
        "    config = super().get_config()\n",
        "    return config\n",
        "\n",
        "input_deserializer = DeSerializeInput()\n",
        "output_deserializer = ReSerializeOutput()\n",
        "\n",
        "serialized_inputs = {\n",
        "    model.inputs[0].name: tf.keras.Input(shape=[], dtype='string', name='array_image')\n",
        "}\n",
        "updated_model_input = input_deserializer(serialized_inputs)\n",
        "updated_model = model(updated_model_input)\n",
        "updated_model = output_deserializer(updated_model)\n",
        "updated_model= tf.keras.Model(serialized_inputs, updated_model)"
      ],
      "metadata": {
        "id": "RPvhaCor8peS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the model name\n",
        "MODEL_NAME = 'MODEL_NAME'\n",
        "# Replace your-bucket with your bucket name.\n",
        "MODEL_DIR = 'gs://your-bucket/' + MODEL_NAME\n",
        "updated_model.save(MODEL_DIR)"
      ],
      "metadata": {
        "id": "-fwrQZvI8t5x"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
